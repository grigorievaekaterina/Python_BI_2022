# -*- coding: utf-8 -*-
"""HW_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pkJrGfWXxG1cZQW8GIlZWeUAwO_9aZuF

В формулировке заданий будет использоваться понятие **worker**. Это слово обозначает какую-то единицу параллельного выполнения, в случае питона это может быть **поток** или **процесс**, выбирайте то, что лучше будет подходить к конкретной задаче
"""

import concurrent.futures
import requests
from threading import Thread
import time
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
import multiprocessing

"""# Задание 1 (7 баллов)

В одном из заданий по ML от вас требовалось написать кастомную реализацию Random Forest. Её проблема состоит в том, что она работает медленно, так как использует всего один поток для работы. Добавление параллельного программирования в код позволит получить существенный прирост в скорости обучения и предсказаний.

В данном задании от вас требуется добавить возможность обучать случайный лес параллельно и использовать параллелизм для предсказаний. Для этого вам понадобится:
1. Добавить аргумент `n_jobs` в метод `fit`. `n_jobs` показывает количество worker'ов, используемых для распараллеливания
2. Добавить аргумент `n_jobs` в методы `predict` и `predict_proba`
3. Реализовать функционал по распараллеливанию в данных методах

В результате код `random_forest.fit(X, y, n_jobs=2)` и `random_forest.predict(X, y, n_jobs=2)` должен работать в ~1.5-2 раза быстрее, чем `random_forest.fit(X, y, n_jobs=1)` и `random_forest.predict(X, y, n_jobs=1)` соответственно

Если у вас по каким-то причинам нет кода случайного леса из ДЗ по ML, то вы можете написать его заново или попросить у однокурсника. *Детали* реализации ML части оцениваться не будут, НО, если вы поломаете логику работы алгоритма во время реализации параллелизма, то за это будут сниматься баллы

В задании можно использовать только модули из **стандартной библиотеки** питона, а также функции и классы из **sklearn** при помощи которых вы изначально писали лес
"""

from sklearn.base import BaseEstimator
from sklearn.datasets import make_classification


class RandomForestClassifierCustom(BaseEstimator):
    def __init__(
        self, n_estimators=10, max_depth=None, max_features=None, random_state=None):
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.max_features = max_features
        self.random_state = random_state

        self.trees = []
        self.feat_ids_by_tree = []

    def fit(self, X, y, n_jobs=1): #default n_jobs=1 
        self.classes_ = sorted(np.unique(y))
        with concurrent.futures.ThreadPoolExecutor(n_jobs) as pool:
            futures = []
            for i in range(self.n_estimators):  
                np.random.seed(self.random_state + i)
                ind = np.random.choice(X.shape[1], size=self.max_features, replace=False)
                self.feat_ids_by_tree.append(ind)
                pseudo = np.random.choice(len(X), size=len(X))
                X_cur = X[:, ind][pseudo]
                y_cur = y[pseudo]
                tree = DecisionTreeClassifier(max_depth=self.max_depth, 
                                            max_features=self.max_features,
                                            random_state = self.random_state)
                futures.append(pool.submit(tree.fit, X_cur, y_cur))
                self.trees.append(tree)
            for future in concurrent.futures.as_completed(futures):
                pass
        return self

    def predict_proba(self, X, n_jobs=1): #default n_jobs=1
        proba = 0
        with concurrent.futures.ThreadPoolExecutor(n_jobs) as pool:
            futures = []        
            for i in range(self.n_estimators):           
                futures.append(pool.submit(self.trees[i].predict_proba, X[:, self.feat_ids_by_tree[i]]))
            for future in concurrent.futures.as_completed(futures):
                proba += future.result()
        return proba/self.n_estimators

    def predict(self, X, n_jobs=1): #default n_jobs=1
        probas = self.predict_proba(X, n_jobs=n_jobs)
        predictions = np.argmax(probas, axis=1)        
        return predictions
    

X, y = make_classification(n_samples=100000)

random_forest = RandomForestClassifierCustom(max_depth=30, n_estimators=10, max_features=2, random_state=42)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# _ = random_forest.fit(X, y, n_jobs=1)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# preds_1 = random_forest.predict(X, n_jobs=1)

random_forest = RandomForestClassifierCustom(max_depth=30, n_estimators=10, max_features=2, random_state=42)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# _ = random_forest.fit(X, y, n_jobs=2)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# preds_2 = random_forest.predict(X, n_jobs=2)

(preds_1 == preds_2).all()   # Количество worker'ов не должно влиять на предсказания

"""#### Какие есть недостатки у вашей реализации параллельного Random Forest (если они есть)? Как это можно исправить? Опишите словами, можно без кода (+1 дополнительный балл)

Мне кажется, что несильно получилось уменьшить время выполнения (~1.45 раза).

# Задание 2 (9 баллов)

Напишите декоратор `memory_limit`, который позволит ограничивать использование памяти декорируемой функцией.

Декоратор должен принимать следующие аргументы:
1. `soft_limit` - "мягкий" лимит использования памяти. При превышении функцией этого лимита должен будет отображён **warning**
2. `hard_limit` - "жёсткий" лимит использования памяти. При превышении функцией этого лимита должно будет брошено исключение, а функция должна немедленно завершить свою работу
3. `poll_interval` - интервал времени (в секундах) между проверками использования памяти

Требования:
1. Потребление функцией памяти должно отслеживаться **во время выполнения функции**, а не после её завершения
2. **warning** при превышении `soft_limit` должен отображаться один раз, даже если функция переходила через этот лимит несколько раз
3. Если задать `soft_limit` или `hard_limit` как `None`, то соответствующий лимит должен быть отключён
4. Лимиты должны передаваться и отображаться в формате `<number>X`, где `X` - символ, обозначающий порядок единицы измерения памяти ("B", "K", "M", "G", "T", ...)
5. В тексте warning'ов и исключений должен быть указан текщий объём используемой памяти и величина превышенного лимита

В задании можно использовать только модули из **стандартной библиотеки** питона, можно писать вспомогательные функции и/или классы

В коде ниже для вас предопределены некоторые полезные функции, вы можете ими пользоваться, а можете не пользоваться
"""

import os
import psutil
import time
import warnings


def get_memory_usage():    # Показывает текущее потребление памяти процессом
    process = psutil.Process(os.getpid())
    mem_info = process.memory_info()
    return mem_info.rss


def bytes_to_human_readable(n_bytes):
    symbols = ('K', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y')
    prefix = {}
    for idx, s in enumerate(symbols):
        prefix[s] = 1 << (idx + 1) * 10
    for s in reversed(symbols):
        if n_bytes >= prefix[s]:
            value = float(n_bytes) / prefix[s]
            return f"{value:.2f}{s}"
    return f"{n_bytes}B"

def bytes_to_float(n):
    symbols_to_bytes = {'B': 1, 'K': 1024, 'M': 1024**2, 
                        'G': 1024**3, 'T': 1024**4, 'P': 1024**5,
                        'E': 1024**6,  'Z': 1024**7,  'Y': 1024**8}
    return float(n[:-1])*symbols_to_bytes[n[-1].upper()]

def memory_limit(soft_limit=None, hard_limit=None, poll_interval=1):
    def wrapper(func):
        def inner_function(*args, **kwargs):
            start = time.time()
            max = 0
            soft_bytes = None
            hard_bytes = None
            warning = False
            
            if soft_limit:
                soft_bytes = bytes_to_float(soft_limit)         
            if hard_limit:
                hard_bytes = bytes_to_float(hard_limit)   

            while True:
                memory = get_memory_usage()
                if memory > max:
                    max = memory               
                if hard_bytes and max > hard_bytes:
                    raise MemoryError(f"Memory hard limit exceeded: {bytes_to_human_readable(max)} > {hard_limit}")                
                if soft_bytes and not warning and max > soft_bytes:
                    warning = True
                    warnings.warn(f"Memory soft limit exceeded: {bytes_to_human_readable(max)} > {soft_limit}")                
                result = func(*args, **kwargs)
                
                if memory == get_memory_usage():
                    break               
                if (time.time() - start) > poll_interval:
                    start = time.time()
                    continue
            
            return result        
        return inner_function
    return wrapper

@memory_limit(soft_limit="512M", hard_limit="1.5G", poll_interval=0.1)
def memory_increment():
    """
    Функция для тестирования
    
    В течение нескольких секунд достигает использования памяти 1.89G
    Потребление памяти и скорость накопления можно варьировать, изменяя код
    """
    lst = []
    for i in range(50000000):
        if i % 500000 == 0:
            time.sleep(0.1)
        lst.append(i)
    return lst

memory_increment()

@memory_limit(soft_limit="100M", hard_limit="10G", poll_interval=0.1)
def memory_increment():
    """
    Функция для тестирования
    
    В течение нескольких секунд достигает использования памяти 1.89G
    Потребление памяти и скорость накопления можно варьировать, изменяя код
    """
    lst = []
    for i in range(50000000):
        if i % 500000 == 0:
            time.sleep(0.1)
        lst.append(i)
    return lst

memory_increment()

"""# Задание 3 (11 баллов)

Напишите функцию `parallel_map`. Это должна быть **универсальная** функция для распараллеливания, которая эффективно работает в любых условиях.

Функция должна принимать следующие аргументы:
1. `target_func` - целевая функция (обязательный аргумент)
2. `args_container` - контейнер с позиционными аргументами для `target_func` (по-умолчанию `None` - позиционные аргументы не передаются)
3. `kwargs_container` - контейнер с именованными аргументами для `target_func` (по-умолчанию `None` - именованные аргументы не передаются)
4. `n_jobs` - количество workers, которые будут использованы для выполнения (по-умолчанию `None` - количество логических ядер CPU в системе)

Функция должна работать аналогично `***PoolExecutor.map`, применяя функцию к переданному набору аргументов, но с некоторыми дополнениями и улучшениями
    
Поскольку мы пишем **универсальную** функцию, то нам нужно будет выполнить ряд требований, чтобы она могла логично и эффективно работать в большинстве ситуаций

1. `target_func` может принимать аргументы любого вида в любом количестве
2. Любые типы данных в `args_container`, кроме `tuple`, передаются в `target_func` как единственный позиционный аргумент. `tuple` распаковываются в несколько аргументов
3. Количество элементов в `args_container` должно совпадать с количеством элементов в `kwargs_container` и наоборот, также значение одного из них или обоих может быть равно `None`, в иных случаях должна кидаться ошибка (оба аргумента переданы, но размеры не совпадают)

4. Функция должна выполнять определённое количество параллельных вызовов `target_func`, это количество зависит от числа переданных аргументов и значения `n_jobs`. Сценарии могут быть следующие
    + `args_container=None`, `kwargs_container=None`, `n_jobs=None`. В таком случае функция `target_func` выполнится параллельно столько раз, сколько на вашем устройстве логических ядер CPU
    + `args_container=None`, `kwargs_container=None`, `n_jobs=5`. В таком случае функция `target_func` выполнится параллельно **5** раз
    + `args_container=[1, 2, 3]`, `kwargs_container=None`, `n_jobs=5`. В таком случае функция `target_func` выполнится параллельно **3** раза, несмотря на то, что `n_jobs=5` (так как есть всего 3 набора аргументов для которых нам нужно получить результат, а лишние worker'ы создавать не имеет смысла)
    + `args_container=None`, `kwargs_container=[{"s": 1}, {"s": 2}, {"s": 3}]`, `n_jobs=5`. Данный случай аналогичен предыдущему, но здесь мы используем именованные аргументы
    + `args_container=[1, 2, 3]`, `kwargs_container=[{"s": 1}, {"s": 2}, {"s": 3}]`, `n_jobs=5`. Данный случай аналогичен предыдущему, но здесь мы используем и позиционные, и именованные аргументы
    + `args_container=[1, 2, 3, 4]`, `kwargs_container=None`, `n_jobs=2`. В таком случае в каждый момент времени параллельно будет выполняться **не более 2** функций `target_func`, так как нам нужно выполнить её 4 раза, но у нас есть только 2 worker'а.
    + В подобных случаях (из примера выше) должно оптимизироваться время выполнения. Если эти 4 вызова выполняются за 5, 1, 2 и 1 секунды, то параллельное выполнение с `n_jobs=2` должно занять **5 секунд** (не 7 и тем более не 10)

5. `parallel_map` возвращает результаты выполнения `target_func` **в том же порядке**, в котором были переданы соответствующие аргументы
6. Работает с функциями, созданными внутри других функций

Для базового решения от вас не ожидается **сверххорошая** оптимизация по времени и памяти для всех возможных случаев. Однако за хорошо оптимизированную логику работы можно получить до **+3 дополнительных баллов**

Вы можете сделать класс вместо функции, если вам удобнее

В задании можно использовать только модули из **стандартной библиотеки** питона

Ниже приведены тестовые примеры по каждому из требований
"""

def parallel_map(target_func,
                 args_container=None,
                 kwargs_container=None,
                 n_jobs=None):
    # Ваш код здесь

import time


# Это только один пример тестовой функции, ваша parallel_map должна уметь эффективно работать с ЛЮБЫМИ функциями
# Поэтому обязательно протестируйте код на чём-нибудбь ещё
def test_func(x=1, s=2, a=1, b=1, c=1):
    time.sleep(s)
    return a*x**2 + b*x + c

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 2.1
# # Отдельные значения в args_container передаются в качестве позиционных аргументов
# parallel_map(test_func, args_container=[1, 2.0, 3j-1, 4])   # Здесь происходят параллельные вызовы: test_func(1) test_func(2.0) test_func(3j-1) test_func(4)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 2.2
# # Элементы типа tuple в args_container распаковываются в качестве позиционных аргументов
# parallel_map(test_func, [(1, 1), (2.0, 2), (3j-1, 3), 4])    # Здесь происходят параллельные вызовы: test_func(1, 1) test_func(2.0, 2) test_func(3j-1, 3) test_func(4)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 3.1
# # Возможна одновременная передача args_container и kwargs_container, но количества элементов в них должны быть равны
# parallel_map(test_func,
#              args_container=[1, 2, 3, 4],
#              kwargs_container=[{"s": 3}, {"s": 3}, {"s": 3}, {"s": 3}])
# 
# # Здесь происходят параллельные вызовы: test_func(1, s=3) test_func(2, s=3) test_func(3, s=3) test_func(4, s=3)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 3.2
# # args_container может быть None, а kwargs_container задан явно
# parallel_map(test_func,
#              kwargs_container=[{"s": 3}, {"s": 3}, {"s": 3}, {"s": 3}])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 3.3
# # kwargs_container может быть None, а args_container задан явно
# parallel_map(test_func,
#              args_container=[1, 2, 3, 4])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 3.4
# # И kwargs_container, и args_container могут быть не заданы
# parallel_map(test_func)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 3.4
# # И kwargs_container, и args_container могут быть не заданы
# parallel_map(test_func)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 3.5
# # При несовпадении количеств позиционных и именованных аргументов кидается ошибка
# parallel_map(test_func,
#              args_container=[1, 2, 3, 4],
#              kwargs_container=[{"s": 3}, {"s": 3}, {"s": 3}])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 4.1
# # Если функция не имеет обязательных аргументов и аргумент n_jobs не был передан, то она выполняется параллельно столько раз, сколько ваш CPU имеет логических ядер
# # В моём случае это 24, у вас может быть больше или меньше
# parallel_map(test_func)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 4.2
# # Если функция не имеет обязательных аргументов и передан только аргумент n_jobs, то она выполняется параллельно n_jobs раз
# parallel_map(test_func, n_jobs=2)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 4.3
# # Если аргументов для target_func указано МЕНЬШЕ, чем n_jobs, то используется такое же количество worker'ов, сколько было передано аргументов
# parallel_map(test_func,
#              args_container=[1, 2, 3],
#              n_jobs=5)   # Здесь используется 3 worker'a

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 4.4
# # Аналогичный предыдущему случай, но с именованными аргументами
# parallel_map(test_func,
#              kwargs_container=[{"s": 3}, {"s": 3}, {"s": 3}],
#              n_jobs=5)   # Здесь используется 3 worker'a

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 4.5
# # Комбинация примеров 4.3 и 4.4 (переданы и позиционные и именованные аргументы)
# parallel_map(test_func,
#              args_container=[1, 2, 3],
#              kwargs_container=[{"s": 3}, {"s": 3}, {"s": 3}],
#              n_jobs=5)   # Здесь используется 3 worker'a

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 4.6
# # Если аргументов для target_func указано БОЛЬШЕ, чем n_jobs, то используется n_jobs worker'ов
# parallel_map(test_func,
#              args_container=[1, 2, 3, 4],
#              kwargs_container=None,
#              n_jobs=2)   # Здесь используется 2 worker'a

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Пример 4.7
# # Время выполнения оптимизируется, данный код должен отрабатывать за 5 секунд
# parallel_map(test_func,
#              kwargs_container=[{"s": 5}, {"s": 1}, {"s": 2}, {"s": 1}],
#              n_jobs=2)

def test_func2(string, sleep_time=1):
    time.sleep(sleep_time)
    return string

# Пример 5
# Результаты возвращаются в том же порядке, в котором были переданы соответствующие аргументы вне зависимости от того, когда завершился worker
arguments = ["first", "second", "third", "fourth", "fifth"]
parallel_map(test_func2,
             args_container=arguments,
             kwargs_container=[{"sleep_time": 5}, {"sleep_time": 4}, {"sleep_time": 3}, {"sleep_time": 2}, {"sleep_time": 1}])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# 
# def test_func3():
#     def inner_test_func(sleep_time):
#         time.sleep(sleep_time)
#     return parallel_map(inner_test_func, args_container=[1, 2, 3])
# 
# # Пример 6
# # Работает с функциями, созданными внутри других функций
# test_func3()